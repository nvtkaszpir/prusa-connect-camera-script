{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Prusa-Connect-Camera-Script","text":"<p>This project aims to make it easier to use any camera to be used as Prusa Connect camera.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>allows to read images from CSI cameras, USB cameras, RTSP streams, still images...</li> <li>do not send pictures if the printer is offline</li> <li>store data in memory to prevent MicroSD wear out</li> <li>verbose error messages to see if the image capture works</li> <li>ability to run multiple cameras in separate instances</li> <li>ability to run in docker containers (multi-platform  multi-arch)</li> </ul>"},{"location":"#architecture","title":"Architecture","text":"sequenceDiagram     script-&gt;&gt;script: initial checks     script-&gt;&gt;script: start loop     script-&gt;&gt;camera_command: Call camera command     camera_command-&gt;&gt;image_on_disk: camera command writes image to disk     image_on_disk-&gt;&gt;script: script checks image from disk if exits etc     script-&gt;&gt;script: show errors if image_on_disk is missing     script-&gt;&gt;curl: run curl to post image to Prusa Connect API (pass image_on_disk)     curl-&gt;&gt;image_on_disk: curl reads image from disk     curl-&gt;&gt;Prusa Connect: send image to Prusa Connect     Prusa Connect-&gt;&gt;curl: return response code / messages     script-&gt;&gt;script: sleep + end loop"},{"location":"#known-limitations","title":"Known limitations","text":"<ul> <li>this script performs processing of the single camera, if you need more cameras   then just create multiple copies with different settings (see below)</li> <li> <p>Rpi Zero W or older devices may have CPU limitations to process remote streams   or multiple cameras at once</p> </li> <li> <p>I was not able to test EVERY setting so this may still have some bugs</p> </li> <li>Prusa Connect will not show camera image if the printer is not alive, this is   Prusa Connect limitation.</li> <li>default settings are quire generic and thus low camera quality, you need to adjust   them, see advanced configuration at the end</li> </ul>"},{"location":"config.for.camera.csi.legacy/","title":"CSI camera on Raspberry Pi (legacy)","text":"<p>CSI Camera V2 as of Sat 23 Mar 08:47:12 UTC 2024.</p> <p>Example for older operating systems (those with command <code>raspistill</code>):</p> <ul> <li>copy <code>csi-legacy.dist</code> as <code>.env</code> if you want to use Raspberry Pi camera</li> <li>in copied file <code>.env</code> replace <code>token-change-me</code> with the value of the token   you copied</li> <li>in copied file <code>.env</code> replace <code>fingerprint-change-me</code> with some random value,   which is alphanumeric and has at least 16 chars (and max of 40 chars),   for example set it to <code>fingerprint-myprinter-camera-1</code></li> <li>save edited file <code>.env</code></li> </ul> <p>Next, test config.</p>"},{"location":"config.for.camera.csi.legacy/#real-world-scenario","title":"Real world scenario","text":"<p>Some older Rpi 3 with older Debian with basic cam:</p> <pre><code>PRINTER_ADDRESS=127.0.0.1\nPRUSA_CONNECT_CAMERA_TOKEN=token-change-me\nPRUSA_CONNECT_CAMERA_FINGERPRINT=trash-cam-night-video-wide-1\nCAMERA_DEVICE=/dev/video0\nCAMERA_COMMAND=raspistill\nCAMERA_COMMAND_EXTRA_PARAMS=\"--nopreview --mode 640:480 -o\"\n</code></pre>"},{"location":"config.for.camera.csi.libcamera/","title":"CSI camera on Raspberry Pi","text":"<p>CSI Camera V2 as of Sat 23 Mar 08:47:12 UTC 2024.</p> <p>Example for newer operating systems (commands <code>libcamera</code> or <code>rpicam-still</code>):</p> <ul> <li>copy <code>csi.dist</code> as <code>.env</code> if you want to use Raspberry Pi camera</li> <li>in copied file <code>.env</code> replace <code>token-change-me</code> with the value of the token   you copied</li> <li>in copied file <code>.env</code> replace <code>fingerprint-change-me</code> with some random value,   which is alphanumeric and has at least 16 chars (and max of 40 chars),   for example set it to <code>fingerprint-myprinter-camera-1</code></li> <li>save edited file <code>.env</code></li> </ul> <p>Next, test config.</p>"},{"location":"config.for.camera.csi.libcamera/#real-example","title":"Real example","text":"<p>My Rpi Zero W with Raspberry Pi Camera v2 with maximum resolution available:</p> <pre><code>PRINTER_ADDRESS=192.168.1.25\nPRUSA_CONNECT_CAMERA_TOKEN=redacted\nPRUSA_CONNECT_CAMERA_FINGERPRINT=c10eb887-f107-41a4-900e-2c38ea12a11c\nCAMERA_DEVICE=/dev/video0\nCAMERA_COMMAND=rpicam-still\nCAMERA_COMMAND_EXTRA_PARAMS=\"--immediate --nopreview --mode 2592:1944:12:P --lores-width 0 --lores-height 0 --thumb none -o\"\n</code></pre>"},{"location":"config.for.camera.esphome.snapshot/","title":"ESPHome camera snapshot","text":"<p>With esphome camera with snapshot we can use the ultimate power of <code>curl</code> command to fetch the image from the camera.</p>"},{"location":"config.for.camera.esphome.snapshot/#prepare-esphome-device","title":"Prepare esphome device","text":"<p>Configure esphome device:</p> <ul> <li>install esphome camera   on the device and add <code>esp32_camera</code> and <code>esp32_camera_web_server</code> with   <code>snapshot</code> modules:</li> </ul> <pre><code>esp32_camera:\n... (skipped due to the fact there are different modules)\n\nesp32_camera_web_server:\n  - port: 8081\n    mode: snapshot\n</code></pre> <p>Flash the device and wait until it boots and is available.</p>"},{"location":"config.for.camera.esphome.snapshot/#create-config-for-script","title":"Create config for script","text":"<ul> <li>copy <code>esphome-snapshot.dist</code> as <code>.env</code></li> <li>in copied file <code>.env</code> replace <code>token-change-me</code> with the value   of the token you copied</li> <li>in copied file <code>.env</code> replace <code>fingerprint-change-me</code> with some   random value, which is alphanumeric and has at least 16 chars (and max of 40 chars),   for example set it to <code>fingerprint-myprinter3-camera-3</code></li> <li>in copied file <code>.env</code> replace your esphome device address and port   in <code>CAMERA_COMMAND_EXTRA_PARAMS</code></li> <li>save edited file <code>.env</code></li> </ul> <p>Next, test config.</p>"},{"location":"config.for.camera.esphome.snapshot/#real-world-example","title":"Real world example","text":"<p>I have esp32-wrover-dev board with camera + esphome + web ui for camera exposing snapshot frame on port <code>8081</code>.</p> <p>We can use curl to fetch it.</p> <pre><code>PRINTER_ADDRESS=127.0.0.1\nPRUSA_CONNECT_CAMERA_TOKEN=redacted\nPRUSA_CONNECT_CAMERA_FINGERPRINT=06f47777-f179-4025-bd80-9e4cb8db2aed\nCAMERA_DEVICE=/dev/null\nCAMERA_COMMAND=curl\nCAMERA_COMMAND_EXTRA_PARAMS=http://esp32-wrover-0461c8.local:8081/ -o\n</code></pre>"},{"location":"config.for.camera.esphome.stream/","title":"ESPHome camera stream","text":"<p>With esphome camera stream we can use the <code>ffmpeg</code> to fetch the image from the camera stream. It requires a bit more computing power from esp device and the host that runs the image processing.</p> <p>Warning</p> <p>Notice that this is not recommended way due to the amount of consumed resources on the esp32 and the host which processes the video to extract the image.</p> <p>With esp32 ensure to attach camera to the heat radiator or to the esp32 metal package to help it dissipate heat.</p>"},{"location":"config.for.camera.esphome.stream/#prepare-esphome-device","title":"Prepare esphome device","text":"<p>Configure esphome device:</p> <ul> <li>install esphome camera   on the device and add <code>esp32_camera</code> and <code>esp32_camera_web_server</code> with   <code>stream</code> modules:</li> </ul> <pre><code>esp32_camera:\n... (skipped due to the fact there are different modules)\n\nesp32_camera_web_server:\n  - port: 8080\n    mode: stream\n</code></pre> <p>Flash the device and wait until it boots and is available.</p>"},{"location":"config.for.camera.esphome.stream/#create-config-for-script","title":"Create config for script","text":"<ul> <li>copy <code>esphome-stream.dist</code> as <code>.env</code></li> <li>in copied file <code>.env</code> replace <code>token-change-me</code> with the value   of the token you copied</li> <li>in copied file <code>.env</code> replace <code>fingerprint-change-me</code> with some   random value, which is alphanumeric and has at least 16 chars (and max of 40 chars),   for example set it to <code>fingerprint-myprinter3-camera-3</code></li> <li>in copied file <code>.env</code> replace your esphome device address and port   in <code>CAMERA_COMMAND_EXTRA_PARAMS</code></li> <li>notice that <code>-update 1</code> may not be needed in certain ffmpeg versions</li> <li>save edited file <code>.env</code></li> </ul> <p>Next, test config.</p>"},{"location":"config.for.camera.esphome.stream/#real-world-example","title":"Real world example","text":"<p>The same ESP device with stream, notice different port (<code>8080</code>).</p> <pre><code>PRINTER_ADDRESS=127.0.0.1\nPRUSA_CONNECT_CAMERA_TOKEN=token-change-me\nPRUSA_CONNECT_CAMERA_FINGERPRINT=f68336b-8dab-42cd-8729-6abd8855ff63\nCAMERA_DEVICE=/dev/null\nCAMERA_COMMAND=ffmpeg\nCAMERA_COMMAND_EXTRA_PARAMS=\"-y -i 'http://esp32-wrover-0461c8.local:8080/' -vframes 1 -q:v 1 -f image2 -update 1 \"\n</code></pre>"},{"location":"config.for.camera.hls/","title":"Web Cam - HLS stream","text":"<p>HLS is extremely easy to set up and works over plain HTTP protocol, thus it can be very easily proxied and accessed by other clients.</p> <p>Warning</p> <p>DO NOT use VLC to test streams, there are unfortunately problems with it. Please use <code>ffplay</code> from <code>ffmpeg</code> package.</p> <p>You should be able to test the stream locally with <code>ffplay</code> command.</p> <p>For example, if your camera is reachable over address <code>192.168.0.20</code> and port <code>8888</code> under endpoint <code>/stream</code> then below command should show the stream:</p> <pre><code>ffplay http://192.168.0.20:8888/stream/index.m3u8\n</code></pre> <p>If that works, then configuration should be pretty straightforward:</p> <ul> <li>copy <code>ffmpeg-mediamtx-hls.dist</code> as <code>.env</code></li> <li>in copied file <code>.env</code> replace <code>token-change-me</code> with the value   of the token you copied</li> <li>in copied file <code>.env</code> replace <code>fingerprint-change-me</code>   with some random value, which is alphanumeric and has at least 16 chars   (and max of 40 chars), for example set it to <code>fingerprint-myprinter4-camera-4</code></li> <li>in copied file <code>.env</code> replace your RTSP device address <code>raspberry-pi</code>,   port and stream id in <code>CAMERA_COMMAND_EXTRA_PARAMS</code> if needed</li> <li>save edited file <code>.env</code></li> </ul> <p>Next, test config.</p>"},{"location":"config.for.camera.hls/#real-world-example","title":"Real world example","text":"<p>My another Rpi Zero W named <code>hormex</code> has a camera:</p> <ul> <li>CSI</li> </ul> <p>and I'm running <code>mediamtx</code> server to convert those to various streams, one of them is HLS. More about mediamtx is here.</p> <p>So I can have config:</p> <p><code>.stream-hls-csi</code> over HLS:</p> <pre><code>PRINTER_ADDRESS=127.0.0.1\nPRUSA_CONNECT_CAMERA_TOKEN=redacted\nPRUSA_CONNECT_CAMERA_FINGERPRINT=62e8ab72-9766-4ad5-b8b1-174d389fc0d3\nCAMERA_DEVICE=/dev/null\nCAMERA_COMMAND=ffmpeg\nCAMERA_COMMAND_EXTRA_PARAMS=\"-loglevel error -y -i \"http://hormex:8888/cam/index.m3u8\" -f image2 -vframes 1 -pix_fmt yuvj420p \"\n</code></pre>"},{"location":"config.for.camera/","title":"Create config for prusa-connect-camera-script env vars","text":""},{"location":"config.for.camera/#prusa-camera-token","title":"Prusa Camera Token","text":"<p><code>PRUSA_CONNECT_CAMERA_TOKEN</code> should be taken from earlier step.</p>"},{"location":"config.for.camera/#fingerprint","title":"Fingerprint","text":"<p><code>PRUSA_CONNECT_CAMERA_FINGERPRINT</code> should be unique and set only once for each camera.</p> <p>Fingerprint can be easily generated using command:</p> <pre><code>uuidgen\n</code></pre> <p>or via online website, just copy/paste the output as fingerprint value into the config.</p> <p>Warning</p> <p>Do not change fingerprint after launching the script - thus camera is registered and you may need to revert the change or delete and re-add camera again and start from scratch.</p>"},{"location":"config.for.camera/#example-devices","title":"Example devices","text":"<p>Other env vars are set depending on the camera device we want to use.</p>"},{"location":"config.for.camera/#locally-connected","title":"Locally connected","text":"<ul> <li>Raspberry Pi CSI camera - libcamera (recommended)</li> <li>Raspberry Pi CSI camera - legacy</li> <li>USB camera</li> </ul>"},{"location":"config.for.camera/#web-cams","title":"Web cams","text":""},{"location":"config.for.camera/#generic","title":"Generic","text":"<ul> <li>Snapshot cams (recommended)</li> <li>MJPG streaming cams</li> <li>RTSP streaming cams</li> </ul>"},{"location":"config.for.camera/#specific-example","title":"Specific example","text":"<ul> <li>ESPHome via camera snapshot (recommended)</li> <li>ESPHome via camera stream</li> </ul>"},{"location":"config.for.camera/#next","title":"Next","text":"<p>Next, test config.</p>"},{"location":"config.for.camera.mjpg/","title":"Web Cam - MJPG stream","text":"<p>This processing requires ffmpeg package.</p> <p>Most standalone webcams are actually mjpg cams, they send infinite motion jpeg stream over specific URL.</p> <p>The best option to check what is the URL is in the camera manual, or if you open web UI of the camera and see the stream image then right click on the image and select Inspect to see the URL for the image - copy that URL.</p> <p>You should be able to test the stream locally with <code>ffplay</code> command.</p> <p>For example, if your camera is reachable over address <code>192.168.0.20</code> and port <code>8000</code> under endpoint <code>/ipcam/mjpeg.cgi</code> then below command should show the stream:</p> <pre><code>ffplay http://192.168.0.20:8000/ipcam/mjpeg.cgi\n</code></pre> <p>There may be some user and password in the URL.</p> <p>If that works, then configuration should be pretty straightforward:</p> <ul> <li>copy <code>ffmpeg-mjpg-stream.dist</code> as <code>.env</code></li> <li>in copied file <code>.env</code> replace <code>token-change-me</code> with the value   of the token you copied</li> <li>in copied file <code>.env</code> replace <code>fingerprint-change-me</code>   with some random value, which is alphanumeric and has at least 16 chars   (and max of 40 chars), for example set it to <code>fingerprint-myprinter4-camera-4</code></li> <li>in copied file <code>.env</code> replace your RTSP device address <code>raspberry-pi</code>,   port and stream id in <code>CAMERA_COMMAND_EXTRA_PARAMS</code> if needed</li> <li>save edited file <code>.env</code></li> </ul> <p>Next, test config.</p>"},{"location":"config.for.camera.mjpg/#unverified-example","title":"Unverified example","text":"<p>Beagle Camera stream - if I remember correctly, the camera URL to the stream is something like <code>http://192.168.2.92/ipcam/mjpeg.cgi</code></p> <p>Replace <code>192.168.2.92</code> with your address in the example below.</p> <pre><code>PRINTER_ADDRESS=127.0.0.1\nPRUSA_CONNECT_CAMERA_TOKEN=token-change-me\nPRUSA_CONNECT_CAMERA_FINGERPRINT=fingerprint-change-me\nCAMERA_DEVICE=/dev/null\nCAMERA_COMMAND=ffmpeg\nCAMERA_COMMAND_EXTRA_PARAMS=\"-y -i 'http://192.168.2.92/ipcam/mjpeg.cgi' -vframes 1 -q:v 1 -f image2 -update 1 \"\n</code></pre> <p>Notice that it is better to use a snapshot instead of stream if available, see here.</p>"},{"location":"config.for.camera.mjpg/#motioneye","title":"MotionEye","text":"<p>First, please see MotionEye in order to to configure the camera.</p> <p>Notice that maybe you should switch to a snapshot, which is much more convenient.</p> <p>Assuming you want to get first camera stream on port <code>9081</code>:</p> <pre><code>PRINTER_ADDRESS=127.0.0.1\nPRUSA_CONNECT_CAMERA_TOKEN=redacted\nPRUSA_CONNECT_CAMERA_FINGERPRINT=06f47777-f179-4025-bd80-9e4cb8db2aed\nCAMERA_DEVICE=/dev/null\nCAMERA_COMMAND=ffmpeg\nCAMERA_COMMAND_EXTRA_PARAMS=\"-y -i 'http://motion-eye.local:9081' -vframes 1 -q:v 1 -f image2 -update 1 \"\n</code></pre> <p>If you run the script on the same host as MotionEye you could just use <code>localhost</code> or <code>0.0.0.0</code> for the host, keeping the port as is.</p>"},{"location":"config.for.camera.motioneye/","title":"MotionEye","text":"<p>MotionEye allows to expose current image or a stream per camera.</p>"},{"location":"config.for.camera.motioneye/#camera-configuration","title":"Camera configuration","text":"<ul> <li>Go to selected camera, click on its settings (top right corner icon)</li> <li>on the left scroll down to <code>Video streaming</code> section and make sure it is enabled (there is a slider on the left and it should show <code>[I]</code>).</li> <li>select <code>Streaming Port</code> and set <code>Authentication mode</code> to <code>Disabled</code>.</li> <li>remember to save the changes</li> </ul> <p>Now there are <code>Useful URLs</code> which can be used in two ways to get images</p> <ul> <li><code>Snapshot URL</code> - the easiest, and recommended</li> <li><code>Streaming URL</code> - this one is more cpu consuming, and it's mjpeg</li> </ul>"},{"location":"config.for.camera.motioneye/#snapshot-url","title":"Snapshot URL","text":"<p>First camera snapshot should be available under address such as</p> <p><code>http://&lt;motioneye-ip&gt;:8765/picture/1/current/</code></p> <p>If you click on the URL in incognito mode it should present the image. If not, check troubleshooting for MotionEye.</p> <p>If that works, then please see snapshot.</p>"},{"location":"config.for.camera.motioneye/#streaming-url","title":"Streaming URL","text":"<p>Camera stream for the first camera instance should be available under address such as</p> <p><code>http://&lt;motioneye-ip&gt;:9081/</code></p> <p>If you click on the URL in incognito mode it should present the stream.</p> <p>Optionally you could try <code>ffplay http://&lt;motioneye-ip&gt;:9081/</code> to test the video. If not, check troubleshooting for MotionEye.</p> <p>If that works, then please see mjpg.</p>"},{"location":"config.for.camera.rtsp/","title":"Web Cam - RTSP stream","text":"<p>Warning</p> <p>DO NOT use VLC to test streams, there are unfortunately problems with it. Please use <code>ffplay</code> from <code>ffmpeg</code> package.</p> <p>You have some options such as TCP or UDP stream (whatever..). This should work with any other camera (usually there is a different port per stream)</p> <p>You should be able to test the stream locally with <code>ffplay</code> command.</p> <p>For example, if your camera is reachable over address <code>192.168.0.20</code> and port <code>8000</code> under endpoint <code>/stream</code> then below command should show the stream:</p> <pre><code>ffplay rtsp://192.168.0.20:8000/stream\n</code></pre> <p>If that works, then configuration should be pretty straightforward:</p> <ul> <li>copy <code>ffmpeg-mediamtx-rtsp-tcp.dist</code> as <code>.env</code></li> <li>in copied file <code>.env</code> replace <code>token-change-me</code> with the value   of the token you copied</li> <li>in copied file <code>.env</code> replace <code>fingerprint-change-me</code>   with some random value, which is alphanumeric and has at least 16 chars   (and max of 40 chars), for example set it to <code>fingerprint-myprinter4-camera-4</code></li> <li>in copied file <code>.env</code> replace your RTSP device address <code>raspberry-pi</code>,   port and stream id in <code>CAMERA_COMMAND_EXTRA_PARAMS</code> if needed</li> <li>save edited file <code>.env</code></li> </ul> <p>You can try with <code>UDP</code>, but you may not get it ;-)</p> <p>Next, test config.</p>"},{"location":"config.for.camera.rtsp/#real-world-example","title":"Real world example","text":"<p>My another Rpi Zero W named <code>hormex</code> has two cameras:</p> <ul> <li>CSI</li> <li>endoscope on /dev/video</li> </ul> <p>and I'm running <code>mediamtx</code> server to convert those to RTSP streams. More about mediamtx is here.</p> <p>So I can have two configs:</p> <p><code>.stream-csi</code> over UDP:</p> <pre><code>PRINTER_ADDRESS=127.0.0.1\nPRUSA_CONNECT_CAMERA_TOKEN=redacted\nPRUSA_CONNECT_CAMERA_FINGERPRINT=62e8ab72-9766-4ad5-b8b1-174d389fc0d3\nCAMERA_DEVICE=/dev/null\nCAMERA_COMMAND=ffmpeg\nCAMERA_COMMAND_EXTRA_PARAMS=\"-loglevel error -y -rtsp_transport udp -i \"rtsp://hormex:8554/cam\" -f image2 -vframes 1 -pix_fmt yuvj420p \"\n</code></pre> <p><code>.stream-endo</code> over TCP:</p> <pre><code>PRINTER_ADDRESS=127.0.0.1\nPRUSA_CONNECT_CAMERA_TOKEN=redacted\nPRUSA_CONNECT_CAMERA_FINGERPRINT=01a67af8-86a3-45c7-b6e2-39e9d086b367\nCAMERA_DEVICE=/dev/null\nCAMERA_COMMAND=ffmpeg\nCAMERA_COMMAND_EXTRA_PARAMS=\"-loglevel error -y -rtsp_transport tcp -i \"rtsp://hormex:8554/endoscope\" -f image2 -vframes 1 -pix_fmt yuvj420p \"\n</code></pre>"},{"location":"config.for.camera.snapshot/","title":"Web Cam - snapshot","text":"<p>Some cameras expose single image snapshot under specific URL. we can use the ultimate power of <code>curl</code> command to fetch the image from the camera.</p> <p>This is the preferred way to use web cams because right now Prusa Connect do not support streams, and thus there is no point in wasting CPU on that.</p> <p>The best option to check what is the URL is in the camera manual, or if you open web UI of the camera and see the still image then right click on the image and select Inspect to see the URL for the image - copy that URL.</p> <p>You should be able to test the stream locally with <code>ffplay</code> command.</p> <p>For example, if your camera is reachable over address <code>192.168.0.20</code> and port <code>8001</code> under endpoint <code>/snap.jpg</code> then below command should show the image:</p> <pre><code>curl -vvv http://another-cam.local:8081/snap.jpg -o snap.jpg\n</code></pre> <p>then you should see in the output something like <code>Content-Type: image/jpeg</code>, then you are good - see <code>snap.jpg</code> in the folder you executed the command.</p>"},{"location":"config.for.camera.snapshot/#create-config-for-script","title":"Create config for script","text":"<ul> <li>copy <code>snapshot.dist</code> as <code>.env</code></li> <li>in copied file <code>.env</code> replace <code>token-change-me</code> with the value   of the token you copied</li> <li>in copied file <code>.env</code> replace <code>fingerprint-change-me</code> with some   random value, which is alphanumeric and has at least 16 chars (and max of 40 chars),   for example set it to <code>fingerprint-myprinter3-camera-3</code></li> <li>in copied file <code>.env</code> replace your esphome device address and port   in <code>CAMERA_COMMAND_EXTRA_PARAMS</code></li> <li>save edited file <code>.env</code></li> </ul> <p>Next, test config.</p>"},{"location":"config.for.camera.snapshot/#real-world-example","title":"Real world example","text":""},{"location":"config.for.camera.snapshot/#esp32-with-esphome","title":"esp32 with esphome","text":"<p>For more in-depth details see esphome snapshot.</p> <p>I have esp32-wrover-dev board with camera + esphome + web ui for camera exposing snapshot frame on port <code>8081</code>.</p> <p>We can use curl to fetch it.</p> <pre><code>PRINTER_ADDRESS=127.0.0.1\nPRUSA_CONNECT_CAMERA_TOKEN=redacted\nPRUSA_CONNECT_CAMERA_FINGERPRINT=06f47777-f179-4025-bd80-9e4cb8db2aed\nCAMERA_DEVICE=/dev/null\nCAMERA_COMMAND=curl\nCAMERA_COMMAND_EXTRA_PARAMS=http://esp32-wrover-0461c8.local:8081/ -o\n</code></pre>"},{"location":"config.for.camera.snapshot/#beagle-camera","title":"Beagle Camera","text":"<p>This is not tested, I do not own such camera so hard to tell if this is right.</p> <p>Camera URL for snapshot <code>http://192.168.2.92/images/snapshot0.jpg</code> so the config should be like below:</p> <pre><code>PRINTER_ADDRESS=127.0.0.1\nPRUSA_CONNECT_CAMERA_TOKEN=redacted\nPRUSA_CONNECT_CAMERA_FINGERPRINT=06f47777-f179-4025-bd80-9e4cb8db2aed\nCAMERA_DEVICE=/dev/null\nCAMERA_COMMAND=curl\nCAMERA_COMMAND_EXTRA_PARAMS=http://192.168.2.92/images/snapshot0.jpg -o\n</code></pre>"},{"location":"config.for.camera.snapshot/#motioneye","title":"MotionEye","text":"<p>First, please see MotionEye in order to to configure the camera.</p> <p>Assuming you want to get first camera snapshot (camera number <code>1</code>):</p> <pre><code>PRINTER_ADDRESS=127.0.0.1\nPRUSA_CONNECT_CAMERA_TOKEN=redacted\nPRUSA_CONNECT_CAMERA_FINGERPRINT=06f47777-f179-4025-bd80-9e4cb8db2aed\nCAMERA_DEVICE=/dev/null\nCAMERA_COMMAND=curl\nCAMERA_COMMAND_EXTRA_PARAMS=http://motioneye-ip:8765/picture/1/current/ -o\n</code></pre> <p>If you run the script on the same host as MotionEye you could just use <code>localhost</code> or <code>0.0.0.0</code> for the host, keeping the port as is.</p>"},{"location":"config.for.camera.usb/","title":"USB camera","text":"<p>This should work on any linux distro with any sane camera that you have.</p>"},{"location":"config.for.camera.usb/#how-to-get-info-which-cameras-are-available","title":"How to get info which cameras are available?","text":"<p>Run <code>v4l2-ctl --list-devices</code>.</p> <p>This should show list of devices to use,  where <code>/dev/video0</code> is a device name.</p> <p>Notice that not every device is an actual camera.</p>"},{"location":"config.for.camera.usb/#how-to-get-what-modes-are-available-for-the-camera","title":"How to get what modes are available for the camera?","text":"<p>The quick all-in one output for camera <code>/dev/video0</code> is</p> <pre><code>v4l2-ctl -d /dev/video0 --all\n</code></pre> <p>For more details about formats it is better to use <code>v4l2-ctl --list-formats-ext -d /dev/video0</code></p>"},{"location":"config.for.camera.usb/#prepare-config","title":"Prepare config","text":"<ul> <li>copy <code>usb.dist</code> as <code>.env</code></li> <li>in copied file <code>.env</code> replace <code>token-change-me</code> with the value of the token   you copied</li> <li>in copied file <code>.env</code> replace <code>fingerprint-change-me</code> with some random value,   which is alphanumeric and has at least 16 chars (and max of 40 chars),   for example set it to <code>fingerprint-myprinter2-camera-2</code></li> <li>in copied file <code>.env</code> replace  <code>/dev/video0</code> with desired device in <code>CAMERA_DEVICE</code></li> <li>save edited file <code>.env</code></li> </ul> <p>Next, test config.</p> <p>Note: if you have more cameras you probably want to use device by-id or by-path, see tuning for more details.</p>"},{"location":"config.for.camera.usb/#real-world-example","title":"Real world example","text":"<p>Raspberry Pi Zero W with endoscope camera over USB, registered as <code>/dev/video1</code>:</p> <pre><code>PRINTER_ADDRESS=192.168.1.25\nPRUSA_CONNECT_CAMERA_TOKEN=redacted\nPRUSA_CONNECT_CAMERA_FINGERPRINT=7054ba85-bc19-4eb9-badc-6129575d9651\nCAMERA_DEVICE=/dev/video1\nCAMERA_COMMAND=fswebcam\nCAMERA_COMMAND_EXTRA_PARAMS=\"--resolution 1280x960 --no-banner\"\n</code></pre> <p>Microsoft LifeCam HD-3000, USB, to avoid image capture tearing we skip first 10 frames <code>-S 10</code> which also helps to set up proper auto exposure and white balance.</p> <pre><code>PRINTER_ADDRESS=192.168.1.25\nPRUSA_CONNECT_CAMERA_TOKEN=redacted\nPRUSA_CONNECT_CAMERA_FINGERPRINT=7054ba85-bc19-4eb9-badc-6129575d9651\nCAMERA_DEVICE=/dev/video4\nCAMERA_COMMAND=fswebcam\nCAMERA_COMMAND_EXTRA_PARAMS=\"-S 10 --resolution 1280x720 --no-banner -s auto_exposure=1,brightness=128,contrast=5\"\n</code></pre>"},{"location":"configuration.env.full/","title":"Configuration Env Vars","text":"<p>Config for camera is to the script as environment variables (env vars).</p> <ul> <li> <p><code>SLEEP</code> - sleep time in seconds between image captures,   notice that Prusa Connect accepts images at most every 10s or slower.   Default value <code>10</code>.</p> </li> <li> <p><code>PRINTER_ADDRESS</code> - Printer address to ping, if address is unreachable there   is no point in sending an image. Set to <code>127.0.0.1</code> to always send images.   Set to empty value to disable ping check and always send images.   Default value <code>127.0.0.1</code>. Notice that if the printer is marked as offline   in Prusa Connect then uploaded images will be uploaded but they are discarded   by Prusa Connect.</p> </li> <li> <p><code>PRUSA_CONNECT_CAMERA_TOKEN</code> - required, Prusa Connect API key</p> </li> <li> <p><code>PRUSA_CONNECT_CAMERA_FINGERPRINT</code> - required, Prusa Connect camera fingerprint,   use for example cli <code>uuidgen</code> or web   to generate it, it must be at least 16 alphanumeric chars, 40 max.   Remember not to change this if it was already set, otherwise you need to   remove and add the camera again.</p> </li> <li> <p><code>CAMERA_DEVICE</code> - camera device to use, if you use Raspberry Pi camera   attached to the CSI via camera ribbon then leave as is.   Default <code>/dev/video0</code>, which points to the first detected camera.   If you have more cameras you probably want to use device   by-id or by-path, see tuning for more details.</p> </li> <li> <p><code>CAMERA_SETUP_COMMAND</code> - camera setup command and params executed before   taking image, default value is empty, because some cameras do not support it,   in general you want to use something like v4l2-ctl parameters,   then for example   <code>setup_command=v4l2-ctl --set-ctrl brightness=10,gamma=120 -d $CAMERA_DEVICE</code>   will translate to:   <code>v4l2-ctl --set-ctrl brightness=10,gamma=120 -d /dev/video0</code></p> </li> <li> <p><code>CAMERA_COMMAND</code> - command used to invoke image capture,   default is <code>rpicam-still</code>,   available options:</p> </li> <li>rpicam-still - using CSI camera + modern Raspberry Pi operating systems since     Debian 11 Bullseye</li> <li>raspistill - using CSI camera + older Raspberry Pi operating systems</li> <li>fswebcam - using USB camera + custom package 'fswebcam'</li> <li> <p>anything else will be processed directly, so for example you could use     'ffmpeg' in here</p> </li> <li> <p><code>CAMERA_COMMAND_EXTRA_PARAMS</code> - extra params passed to the camera program,   passed directly as <code>&lt;command&gt; &lt;extra-params&gt; &lt;output_file&gt;</code>,   some example values per specific camera:    </p> </li> <li> <p>libcamera (rpicam-still)     <code>--immediate --nopreview --mode 2592:1944:12:P --lores-width 0 --lores-height 0 --thumb none -o</code></p> </li> <li>raspistill     <code>--nopreview --mode 2592:1944:12:P -o</code></li> <li>fswebcam     <code>--resolution 1280x960 --no-banner</code></li> <li>ffmpeg, in this case CAMERA_DEVICE is ignored, use it directly in the extra params     <code>-f v4l2 -y -i /dev/video0 -f image2 -vframes 1 -pix_fmt yuvj420p</code></li> </ul> <ul> <li> <p><code>TARGET_DIR</code> -  directory where to save camera images, image per camera will   be overwritten per image capture,   default value <code>/dev/shm</code> so that we do not write to microSD cards or read only   filesystems/containers. <code>/dev/shm</code> is a shared memory space, if you have more   printers you may need to increase this value on system level.</p> </li> <li> <p><code>CURL_EXTRA_PARAMS</code> - extra params to curl when pushing an image,   default empty value, but you could for example add additional params if needed   such as <code>-k</code> if using TLS proxy with self-signed certificate</p> </li> <li> <p><code>PRUSA_CONNECT_URL</code> - Prusa Connect endpoint where to post images,   default value <code>https://webcam.connect.prusa3d.com/c/snapshot</code>.   You could put here Prusa Connect Proxy if you use one.</p> </li> </ul> <p>For more in-depth details (no need to repeat them here) please see the top of the prusa-connect-camera.sh.</p>"},{"location":"configuration.env/","title":"Configuration Env Vars","text":""},{"location":"configuration.env/#minimum-required-env-vars","title":"Minimum required env vars","text":"<p>Config for camera is to the script as environment variables (env vars).</p> <p>The most important env vars are:</p> <ul> <li><code>PRUSA_CONNECT_CAMERA_TOKEN</code></li> <li><code>PRUSA_CONNECT_CAMERA_FINGERPRINT</code></li> <li><code>CAMERA_COMMAND</code></li> <li><code>CAMERA_COMMAND_EXTRA_PARAMS</code></li> </ul> <p>Those env vars will be filled in the next steps.</p> <p>Full list of env vars can be seen here</p>"},{"location":"configuration.overview/","title":"Configuration Overview","text":"<p>Short overview of actions:</p> <ul> <li>ensure printer is up and running and sending status to Prusa Connect   (otherwise images will be discarded)</li> <li>add new camera to the existing printer in Prusa Connect,   obtain token and generate fingerprint</li> <li>create config for prusa-connect-camera-script env vars</li> <li>test the config</li> <li>install script as systemd service</li> <li>tuning config</li> </ul>"},{"location":"configuration.tuning/","title":"Configuration tuning","text":"<p>Assuming you already have a working camera with basic setup, we can tune it further.</p> <p>Below steps depend on the camera capabilities, thus your mileage may vary.</p> <p>Notice that Prusa Connect has file size limit something about 8MB of the image uploaded, so there may be no point in getting images with super high resolutions.</p>"},{"location":"configuration.tuning/#using-predictable-camera-device-names","title":"Using predictable camera device names","text":"<p>Sometimes devices change their id so once given camera is under <code>/dev/video1</code> while another restart and it is under <code>/dev/video2</code> and swaps with another one.</p> <p>If you want to have a predictable camera identifiers then see directory <code>/dev/v4l/by-id</code> or <code>/dev/v4l/by-path</code> and choose the one that you prefer</p> <p>Example on Raspberry Pi with CSI camera and two USB cameras:</p> <pre><code>pi@hormex:~ $ tree /dev/v4l\n/dev/v4l\n\u251c\u2500\u2500 by-id\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 usb-Generic_USB_Camera_200901010001-video-index0 -&gt; ../../video3\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 usb-Generic_USB_Camera_200901010001-video-index1 -&gt; ../../video4\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 usb-Microsoft_Microsoft\u00ae_LifeCam_HD-3000-video-index0 -&gt; ../../video1\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 usb-Microsoft_Microsoft\u00ae_LifeCam_HD-3000-video-index1 -&gt; ../../video2\n\u2514\u2500\u2500 by-path\n    \u251c\u2500\u2500 platform-bcm2835-codec-video-index0 -&gt; ../../video18\n    \u251c\u2500\u2500 platform-bcm2835-isp-video-index0 -&gt; ../../video20\n    \u251c\u2500\u2500 platform-bcm2835-isp-video-index1 -&gt; ../../video21\n    \u251c\u2500\u2500 platform-bcm2835-isp-video-index2 -&gt; ../../video22\n    \u251c\u2500\u2500 platform-bcm2835-isp-video-index3 -&gt; ../../video23\n    \u251c\u2500\u2500 platform-fd500000.pcie-pci-0000:01:00.0-usb-0:1.3:1.0-video-index0 -&gt; ../../video3\n    \u251c\u2500\u2500 platform-fd500000.pcie-pci-0000:01:00.0-usb-0:1.3:1.0-video-index1 -&gt; ../../video4\n    \u251c\u2500\u2500 platform-fd500000.pcie-pci-0000:01:00.0-usb-0:1.4:1.0-video-index0 -&gt; ../../video1\n    \u251c\u2500\u2500 platform-fd500000.pcie-pci-0000:01:00.0-usb-0:1.4:1.0-video-index1 -&gt; ../../video2\n    \u251c\u2500\u2500 platform-fe801000.csi-video-index0 -&gt; ../../video0\n    \u2514\u2500\u2500 platform-feb10000.codec-video-index0 -&gt; ../../video19\n</code></pre> <p>so now if I want to have a Camera-1 always to point to the LifeCam_HD-3000 I can use:</p> <pre><code>CAMERA_DEVICE=/dev/v4l/by-id/usb-Microsoft_Microsoft\u00ae_LifeCam_HD-3000-video-index0\n</code></pre> <p>and for CSI camera (notice it is not available under <code>by-id</code>):</p> <pre><code>CAMERA_DEVICE=/dev/v4l/by-path/platform-fe801000.csi-video-index0\n</code></pre>"},{"location":"configuration.tuning/#getting-higher-quality-camera-images","title":"Getting higher quality camera images","text":"<p>Use <code>v4l2-ctl</code> to get the list of available resolutions that camera provides and then update it in the env var configs.</p> <p>Run <code>v4l2-ctl --list-formats-ext -d /dev/video0</code> where <code>/dev/video0</code> is a device listed from command above.</p> <p>Example output:</p> <pre><code>v4l2-ctl --list-formats-ext -d /dev/video1\nioctl: VIDIOC_ENUM_FMT\n  Type: Video Capture\n\n  [0]: 'MJPG' (Motion-JPEG, compressed)\n    Size: Discrete 640x480\n      Interval: Discrete 0.033s (30.000 fps)\n      Interval: Discrete 0.033s (30.000 fps)\n    Size: Discrete 640x360\n      Interval: Discrete 0.033s (30.000 fps)\n    Size: Discrete 352x288\n      Interval: Discrete 0.033s (30.000 fps)\n    Size: Discrete 320x240\n      Interval: Discrete 0.033s (30.000 fps)\n    Size: Discrete 176x144\n      Interval: Discrete 0.033s (30.000 fps)\n    Size: Discrete 160x120\n      Interval: Discrete 0.033s (30.000 fps)\n    Size: Discrete 800x600\n      Interval: Discrete 0.033s (30.000 fps)\n    Size: Discrete 1280x720\n      Interval: Discrete 0.033s (30.000 fps)\n    Size: Discrete 1280x960\n      Interval: Discrete 0.033s (30.000 fps)\n    Size: Discrete 640x480\n      Interval: Discrete 0.033s (30.000 fps)\n      Interval: Discrete 0.033s (30.000 fps)\n  [1]: 'YUYV' (YUYV 4:2:2)\n    Size: Discrete 640x480\n      Interval: Discrete 0.033s (30.000 fps)\n      Interval: Discrete 0.033s (30.000 fps)\n    Size: Discrete 640x360\n      Interval: Discrete 0.033s (30.000 fps)\n    Size: Discrete 352x288\n      Interval: Discrete 0.033s (30.000 fps)\n    Size: Discrete 320x240\n      Interval: Discrete 0.033s (30.000 fps)\n    Size: Discrete 176x144\n      Interval: Discrete 0.033s (30.000 fps)\n    Size: Discrete 160x120\n      Interval: Discrete 0.033s (30.000 fps)\n    Size: Discrete 800x600\n      Interval: Discrete 0.200s (5.000 fps)\n    Size: Discrete 1280x720\n      Interval: Discrete 0.200s (5.000 fps)\n    Size: Discrete 1280x960\n      Interval: Discrete 0.200s (5.000 fps)\n    Size: Discrete 640x480\n      Interval: Discrete 0.033s (30.000 fps)\n      Interval: Discrete 0.033s (30.000 fps)\n</code></pre> <p>As you can see if I set video to YUYV and with resolution higher than 800x600 I would get only 5 frames per second. For still images this is not a problem, but for video streaming that could be too low and I would have to switch to MJPG (or actually mjpeg in ffmpeg)</p> <p>For Raspberry Cam v2 you could use <code>csi.dist</code> as source and add <code>--mode 2592:1944:12:P</code> to the <code>CAMERA_COMMAND_EXTRA_PARAMS</code>.</p> <p>For certain USB cameras (such as Tracer Endoscope) you should use <code>usb.dist</code> and you should be able to add <code>--resolution 1280x960</code> to the <code>CAMERA_COMMAND_EXTRA_PARAMS</code>.</p>"},{"location":"configuration.tuning/#setting-up-video-camera-controls","title":"Setting up video camera controls","text":"<p>Video controls are things like brightness, auto white balance (awb), exposure and so on.</p> <p>Get device capabilities, especially <code>User controls</code>:</p> <pre><code>v4l2-ctl -d /dev/video0 -l\n</code></pre> <p>Those params can be passed in various ways, depending on the requirement:</p> <ul> <li><code>CAMERA_COMMAND_EXTRA_PARAMS</code> emv var, when using given tool directly</li> <li><code>CAMERA_SETUP_COMMAND</code> env var for some complex use cases</li> <li>other (probably directly via v4l when using ffmpeg, not tested)</li> </ul> <p>and set accordingly parameters you want , you just need to pass them fswebcam, for example:</p> <p><code>CAMERA_COMMAND_EXTRA_PARAMS=--resolution 1280x960 --no-banner -s auto_exposure=1,brightness=128,contrast=5</code></p> <p>For more advanced options see <code>CAMERA_SETUP_COMMAND</code> env var, for example:</p> <pre><code>CAMERA_SETUP_COMMAND=\"v4l2-ctl --set-ctrl brightness=64,gamma=300 -d $CAMERA_DEVICE\"\n</code></pre> <p>remember to restart given camera service.</p> <p>You can try to use <code>guvcview</code> desktop application to check prams in realtime.</p>"},{"location":"configuration.tuning/#image-issues","title":"Image issues","text":"<p>If your captured image has below issues:</p> <ul> <li> <p>the whole image is too dark or too bright and it changes with every capture   so it get too dark or too bright in a matter of minutes:    </p> </li> <li> <p>has some horizontal/vertical super bright/dark areas:    </p> </li> <li> <p>some visible artifacts such as colored blocks or missing image fragments:    </p> </li> </ul> <p>then you may need to initialize camera and capture it with a delay or drop initial number of frames.</p> <p>Notice that sometimes you cannot do much about it (remote cams) because some camera images will be broken anyway, then I suggest changing camera.</p>"},{"location":"configuration.tuning/#dropping-frames","title":"Dropping frames","text":"<p>Usually this is the fastest and with <code>fswebcam</code> it can be achieved by passing <code>-S</code> param, for example</p> <p><code>-S 10</code> will skip 10 first frames.</p>"},{"location":"configuration.tuning/#delay","title":"Delay","text":"<p><code>fswebcam</code>  param <code>-d 2</code> will delay capture for 2 seconds, for some cameras it may help, especially when using auto white balance or auto exposure.</p>"},{"location":"configuration.tuning/#image-flip-and-rotation","title":"Image flip and rotation","text":"<p>You can pass on params to rpicam-still or fswebcam as you want.</p>"},{"location":"configuration.tuning/#rpicam-still","title":"rpicam-still","text":"<p>See <code>rpicam-still --help</code></p> <pre><code>  --hflip      Read out with horizontal mirror\n  --vflip      Read out with vertical flip\n  --rotation   Use hflip and vflip to create the given rotation &lt;angle&gt;\n</code></pre> <p>so for example:</p> <pre><code>CAMERA_COMMAND=rpicam-still\nCAMERA_COMMAND_EXTRA_PARAMS=\"--rotation 90 --immediate --nopreview --thumb none -o\"\n</code></pre>"},{"location":"configuration.tuning/#fswebcam","title":"fswebcam","text":"<p>See <code>fswebcam --help</code></p> <pre><code>  --flip &lt;direction&gt;       Flips the image. (h, v)\n  --crop &lt;size&gt;[,&lt;offset&gt;] Crop a part of the image.\n  --scale &lt;size&gt;           Scales the image.\n  --rotate &lt;angle&gt;         Rotates the image in right angles.\n</code></pre> <p>so for example:</p> <pre><code>CAMERA_COMMAND=fswebcam\nCAMERA_COMMAND_EXTRA_PARAMS=\"--flip v --resolution 640x480 --no-banner\"\n</code></pre> <p>or to skip first 10 frames (<code>-S 10</code>, helps to get proper auto white balance and image exposure) and pass on camera controls:</p> <pre><code>CAMERA_COMMAND=fswebcam\nCAMERA_COMMAND_EXTRA_PARAMS=\"-S 10 --resolution 1280x720 --no-banner -s auto_exposure=1,brightness=128,contrast=5\"\n</code></pre>"},{"location":"configuration.tuning/#ffmpeg","title":"ffmpeg","text":"<p>When curl is not enough and you don't really want to physically rotate your camera, then use ffmpeg for post processing. You can process static images with it, load v4l2 devices... whatever.</p> <p>With ffmpeg you can do interesting things with filters, it will just require more computing power.</p>"},{"location":"configuration.tuning/#adding-v4l2-options","title":"Adding v4l2 options","text":"<p><code>v4l2</code> can be used as alias for <code>video4linux2</code>.</p> <p>You can pass video4linux options to ffmpeg on device initialization, for example:</p> <pre><code>ffmpeg -f v4l2 -pix_fmt mjpeg -video_size 1280x960 -framerate 30 -i /dev/video1 \\\n  -c:v libx264 -preset ultrafast -b:v 6000k -f rtsp rtsp://localhost:$RTSP_PORT/$MTX_PATH\n</code></pre> <p>would instruct ffmpeg to use video4linux and force it to talk to the camera under /dev/video1 and forcing mjpeg encoder, resolution and framerate.</p> <p>This command above is directly taken from mediamtx.</p> <p>For more params, see official ffmpeg docs. Just remember to pass them before defining input (<code>-i /dev/video1</code>).</p>"},{"location":"configuration.tuning/#rotation","title":"Rotation","text":"<p>See here for basic ones.</p> <p>You probably want to use <code>-vf \"transpose=1\"</code> to rotate image 90 degrees clockwise:</p> <pre><code>CAMERA_COMMAND=ffmpeg\nCAMERA_COMMAND_EXTRA_PARAMS=\"-y -i 'http://esp32-wrover-0461c8.local:8080/' -vf 'transpose=1' -vframes 1 -q:v 1 -f image2 -update 1 \"\n</code></pre>"},{"location":"configuration.tuning/#adding-timestamp-to-the-image","title":"Adding timestamp to the image","text":"<p>Add ffmpeg <code>-vf</code> with parameters to the ffmpeg to the processing pipeline before output (<code>-f</code> flag), something like below:</p> <pre><code>-vf 'drawtext=box=1:boxcolor=0x00000000@1:fontsize=60:fontcolor=yellow:text=%{localtime}:x=(w-text_w):y=(h-text_h)'\n</code></pre> <p>This will generate a yellow text in black background box in bottom right corner, and fontsize=60 works well with 1080p.</p> <p>Below is example full command, notice the single quotes are important:</p> <pre><code>CAMERA_COMMAND=ffmpeg\nCAMERA_COMMAND_EXTRA_PARAMS=\"-y -i 'http://esp32-wrover-0461c8.local:8080/' -vf 'transpose=1' -vframes 1 -q:v 1 -vf 'drawtext=box=1:boxcolor=0x00000000@1:fontsize=60:fontcolor=yellow:text=%{localtime}:x=(w-text_w):y=(h-text_h)' -f image2 -update 1 \"\n</code></pre>"},{"location":"configuration.tuning/#other-processing","title":"Other processing","text":"<p>Frankly speaking you can do anything you want with ffmpeg, for example</p> <p><code>-vf transpose=1,shufflepixels=m=block:height=16:width=16</code></p> <p>which effectively shuffles image blocks around. Why? why not :D</p>"},{"location":"configuration.tuning/#image-output-quality","title":"Image output quality","text":"<p>To improve output image quality (especially when doing <code>-r 1 -update 1</code> from the constant stream) then add at the end</p> <pre><code>-b:v 8000k\n</code></pre> <p>For example:</p> <pre><code>ffmpeg -hide_banner -loglevel warning -f hls -i 'http://mediamtx-hls.intra.hlds.pl/cam/index.m3u8' -r 1 -update 1 -vf 'drawtext=box=1:boxcolor=0x00000000@1:fontsize=60:fontcolor=yellow:text=%{localtime}:x=16:y=(h-text_h)' -y -b:v 8000k /data/shared/snapshot.jpg\n</code></pre>"},{"location":"installation/","title":"Installation","text":"<p>Install system packages - assuming Debian based distros on Raspberry Pi OS, which also come in with some pre-installed packages.</p> <p>Below commands should be executed in shell/terminal (on the Raspberry Pi).</p> <p>For most Raspberry Pi Cameras (CSI/USB):</p> <pre><code>sudo apt-get update\nsudo apt-get install -y curl libcamera0 fswebcam git iputils-ping v4l-utils uuid-runtime\n</code></pre> <p>Additional packages for remote cameras - especially the one that are used for streaming:</p> <pre><code>sudo apt-get install -y ffmpeg\n</code></pre> <p>Download this script:</p> <pre><code>mkdir -p /home/pi/src\ncd /home/pi/src\ngit clone https://github.com/nvtkaszpir/prusa-connect-camera-script.git\ncd prusa-connect-camera-script\n</code></pre>"},{"location":"known.limitations/","title":"Known Limitations","text":""},{"location":"known.limitations/#old-curl-version","title":"old curl version","text":"<p>Curl would complain about each option and it would not upload. The error would read something like:</p> <ul> <li><code>curl: option --no-progress-meter: is unknown</code></li> <li><code>curl: option --compressed: is unknown</code></li> <li><code>curl: option --w: is unknown</code></li> </ul> <p>Usually it means your operating system distribution has quite old curl version, and thus certain options are not available - for example you run Raspbian 10 Buster on older Raspberry Pi (see <code>cat /etc/os-release</code>)</p> <p>Fix: you can comment out (or remove) in <code>prusa-connect-camera.sh</code> script lines containing those options by just removing them, until it works. Frankly speaking you REALLY should think about upgrading your operating system.</p>"},{"location":"performance/","title":"Performance","text":"<ul> <li> <p>Raspberry Pi Zero W is able to process CSI camera   (Rpi Cam v2) and USB 2k camera   but it has load average about 1.4, and CPU is quite well utilized, so you may   need to decrease resolution per camera to see how   it goes.</p> </li> <li> <p>for webcams it is always better to choose snapshot   because it requires less computing both on camera and on the host,   otherwise we need to use ffmpeg</p> </li> <li> <p>ffmpeg is usually noticeably slow and cpu intensive, especially if you do more   complex operations</p> </li> </ul>"},{"location":"prusa.connect/","title":"Create new camera in the Prusa Connect","text":"<ul> <li>go to Prusa Connect and log in</li> <li>select <code>Printer</code></li> <li>select <code>Camera</code></li> <li>on the bottom click <code>Add new other camera</code></li> <li>new camera is created, copy <code>Token</code>, this is needed later as   <code>PRUSA_CONNECT_CAMERA_TOKEN</code> env var</li> </ul>"},{"location":"requirements/","title":"Requirements","text":""},{"location":"requirements/#hardware","title":"Hardware","text":"<p>Physical host or virtual machine or container:</p> <ul> <li>probably something like Raspberry Pi Zero W at least, can be without camera</li> <li>more cameras usually requires more compute power</li> </ul> <p>Camera such as:</p> <ul> <li>Raspberry Pi CSI cameras such as Raspberry Pi Cam</li> </ul> <ul> <li>most of USB cameras if they work under Linux</li> <li>esphome cameras using <code>esp32_camera_web_server</code> with <code>snapshot</code> module</li> <li>esphome cameras using <code>esp32_camera_web_server</code> with <code>stream</code> module using <code>ffmpeg</code></li> <li>probably any camera if using <code>ffmpeg</code></li> </ul>"},{"location":"requirements/#software","title":"Software","text":"<p>Linux operating system. Debian based preferred, for example Raspberry Pi OS Lite if you run Raspberry Pi. I use also laptop with Ubuntu 22.04, but I believe with minor tweaks it should work on most distributions (mainly package names are different).</p> <p>Below list uses Debian package names.</p>"},{"location":"requirements/#generic-system-packages","title":"Generic system packages","text":"<ul> <li><code>bash</code> 5.x (what year is it?)</li> <li><code>git</code> (just to install scripts from this repo)</li> <li><code>curl</code></li> <li><code>iputils-ping</code></li> <li><code>uuid-runtime</code> to make generation of camera fingerprint easier</li> </ul>"},{"location":"requirements/#optional-packages","title":"Optional packages","text":"<ul> <li><code>v4l-utils</code> - to detect camera capabilities</li> <li><code>libcamera0</code> - for Rpi CSI cameras</li> <li><code>libraspberrypi-bin</code> or <code>rpicam-apps-lite</code> for Rpi CSI cameras   (should be already installed on Rpi OS)</li> <li><code>fswebcam</code> - for generic USB cameras</li> <li><code>ffmpeg</code> - for custom commands for capturing remote streams</li> <li>you-name-it - for custom commands beyond my imagination</li> </ul>"},{"location":"service.docker/","title":"Install script as docker container","text":"<p>You can run the app as container.</p> <p>Multi-platform images are available at quay.io/kaszpir/prusa-connect-script.</p> <p>Currently available platforms (your system should download desired architecture automatically):</p> <ul> <li>linux/amd64 (64bit)</li> <li>linux/arm64 (64bit)</li> <li>linux/arm/v7 (32bit)</li> </ul>"},{"location":"service.docker/#preparation-of-the-host","title":"Preparation of the host","text":"<p>Install docker on Debian.</p> <p>Optional - you may want to make sure current user is in docker group so it is possible to run containers without using <code>sudo</code>:</p> <pre><code>sudo usermod -a -G docker $(whoami)\n</code></pre> <p>logout and login again, or reboot Raspberry Pi.</p>"},{"location":"service.docker/#preparation-of-env-files-for-docker-command","title":"Preparation of env files for docker command","text":"<p>Notice - you may not have to do it if you use docker-compose (I think...).</p> <p>If you use <code>docker</code> command directly you need to edit env files and remove quotation marks from the files (this is a limitation of the Docker)</p> <p>For example:</p> <pre><code>CAMERA_COMMAND_EXTRA_PARAMS=\"--immediate --nopreview --thumb none -o\"\n</code></pre> <p>becomes</p> <pre><code>CAMERA_COMMAND_EXTRA_PARAMS=--immediate --nopreview --thumb none -o\n</code></pre>"},{"location":"service.docker/#raspberry-pi-csi-or-usb-camera","title":"Raspberry Pi CSI or USB camera","text":"<p>We assume that <code>.csi</code> is a env file with example variables after edit, it is possible to run below command and have screenshots sent to the Prusa Connect.</p> <pre><code>docker run --env-file .csi -v /run/udev:/run/udev:ro -v /dev/:/dev/ --device /dev:/dev --read-only quay.io/kaszpir/prusa-connect-script:03c4886\n</code></pre>"},{"location":"service.docker/#raspberry-pi-and-remote-cams","title":"Raspberry Pi and remote cams","text":"<p>If you use remote camera you can make command even shorter:</p> <pre><code>docker run --env-file .esp32 --read-only quay.io/kaszpir/prusa-connect-script:03c4886\n</code></pre>"},{"location":"service.docker/#other-examples","title":"Other examples","text":"<pre><code>docker run --env-file .docker-csi --device /dev:/dev -v /dev/:/dev/ -v /run/udev:/run/udev:ro -it quay.io/kaszpir/prusa-connect-script:03c4886-arm64\n\ndocker run --env-file .docker-esphome-snapshot --read-only quay.io/kaszpir/prusa-connect-script:03c4886-amd64\ndocker run --env-file .docker-video0 --device /dev:/dev -v /dev/:/dev/ -v /run/udev:/run/udev:ro -it quay.io/kaszpir/prusa-connect-script:03c4886\n</code></pre>"},{"location":"service.docker/#running-multiple-cameras-at-once","title":"Running multiple cameras at once","text":"<p>Create env file per camera and run each container separately.</p>"},{"location":"service.docker/#docker-compose","title":"docker-compose","text":"<p>Instead of running single command per container, you can manage them using docker-compose. Example <code>docker-compose.yaml</code> contains some examples. Some sections are commented out, though.</p> <p>Notice they still require proper env files to work, for example copy usb.dist as .usb, edit its parameters and run <code>docker-compose up</code></p> <p>Notice that you may need to change remote cameras addresses from hostnames to IP addresses.</p> <p>Another notice that sharing <code>/dev/</code> or <code>/dev/shm</code> across different containers with different architectures may be problematic.</p>"},{"location":"service.kubernetes/","title":"Running in Kubernetes","text":"<p>Yes, because why not, especially if you run k3s :D</p> <p>This is just an example but you should be able to adjust it to your needs.</p> <p>See directory for the content you can use with a kustomize.</p>"},{"location":"service.kubernetes/#overview","title":"Overview","text":"<ul> <li> <p>each camera should be a separate kubernetes deployment (or daemonset),   easier to manage.</p> </li> <li> <p>in configs   there is a one file with env vars loaded per deployment,   those env vars MUST BE changed as in env vars.   Also do not use double quotes inside the values.</p> </li> <li> <p>deployment possible using for example kustomize</p> </li> <li> <p>camera device - if you have more cameras you probably want to use device   by-id or by-path, see tuning for more details</p> </li> </ul>"},{"location":"service.kubernetes/#examples","title":"Examples","text":"<ul> <li> <p>deployment-1.yaml   is an example to fetch image from a stream using ffmpeg and with custom   prusa-connect-camera.sh for easier development/iteration.   This is also preferred option when you are not using cameras that are directly   attached to the hosts, but rely on using ffmpeg to fetch images from remote   streams or static images via curl.</p> </li> <li> <p>deployment-2.yaml   is an example how to run it on Raspberry Pi with USB camera using default parameters.   You want to change <code>.spec.nodeName</code> and volumes to point to desired host with   the attached camera.</p> </li> <li> <p>daemonset.yaml   is an example how to run it on Raspberry Pi with USB camera using default parameters.   You want to change <code>.spec.nodeName</code> and volumes to point to desired host with   the attached camera.</p> </li> </ul> <p>The difference between the DaemonSet and Deployment is that with the Deployment kubernetes will try to spawn new pods even if node is not available. DaemonSet it is better when you have to use directly attached devices to the hosts.</p> <p>Of course in that case you will need a daemonset per camera per host, and separate config for each camera/host, and you would need the same with a deployment, but at least when node is gone you are not getting non-schedulable pod every few minutes - imagine hundreds of pods when I turned off one of my Raspberry Pi for a week... With a daemonset when node is gone, then pod is gone and k8s is not trying to spawn new pods.</p>"},{"location":"service.kubernetes/#more-copies","title":"More copies","text":"<p>If you want to add more cameras then you should:</p> <ul> <li>copy example config file from <code>config/</code> and adjust it</li> <li>copy desired deployment.yaml and adjust it</li> <li>update any <code>cam-x</code> references in the deployment.yaml</li> <li>update <code>.spec.nodeName</code> in the deployment.yaml</li> <li> <p>if using direct camera update volumes -  <code>dev-video</code> hostpath to point to the desired   camera device</p> </li> <li> <p>fine tune requests/limits to use less resources if needed</p> </li> </ul>"},{"location":"service.kubernetes/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>just look into the logs of the failing pods</li> <li> <p>some hosts do not have predictable camera names, will have to think about udev   rules how to handle it...</p> </li> <li> <p>not tested with any device operators</p> </li> <li>not tested with istio/traefik whatever.</li> </ul>"},{"location":"service/","title":"Install script as service","text":"<p>Depending on the distro there are various options to configure scripts as service.</p> <ul> <li>systemd - most common service on Linux systems</li> <li>docker - run as Docker container</li> <li>kubernetes - run on Kubernetes</li> </ul> <p>Other - not implemented, do it on your own.</p>"},{"location":"service.systemd/","title":"Install script as systemd service","text":"<p>Depending on the distro there are various options to configure scripts as service. On newer distros Raspberry Pi runs systemd, we will use that.</p> <pre><code>cd /home/pi/src/prusa-connect-camera-script\nsudo cp -f prusa-connect-camera@.service /etc/systemd/system/prusa-connect-camera@.service\nsudo systemctl daemon-reload\n</code></pre>"},{"location":"service.systemd/#configuring-single-camera","title":"Configuring single camera","text":"<p>Assuming that <code>/home/pi/src/prusa-connect-camera-script/.env</code> file was created in previous steps, we use that <code>.env</code> file as example camera config.</p> <p>Notice there is no dot before <code>env</code> in the commands below:</p> <pre><code>sudo systemctl enable prusa-connect-camera@env.service\nsudo systemctl start prusa-connect-camera@env.service\nsudo systemctl status prusa-connect-camera@env.service\n</code></pre> <p>Above commands will enable given service on device restart (reboot), start the service and show current status.</p>"},{"location":"service.systemd/#configure-multiple-cameras","title":"Configure multiple cameras","text":"<p>This project allows spawning multiple systemd units. The suffix after <code>@</code> defines what env file to load from given path. For example if you set unit file name to <code>prusa-connect-camera@csi.service</code> then systemd will load env vars from the file under path <code>/home/pi/src/prusa-connect-camera-script/.csi</code></p> <p>So in short:</p> <ul> <li>copy <code>csi.dist</code> as <code>.csi</code> and edit it</li> <li>copy <code>prusa-connect-camera@.service</code> as <code>prusa-connect-camera@csi.service</code></li> <li>you may additionally edit unit file if you use different config paths</li> <li>run systemctl daemon-reload</li> <li>enable systemd service</li> <li>start systemd service</li> </ul> <pre><code>cd /home/pi/src/prusa-connect-camera-script/\ncp csi.dist .csi\n# edit .csi and set custom command params, token and fingerprint etc...\nsudo systemctl enable prusa-connect-camera@csi.service\nsudo systemctl start prusa-connect-camera@csi.service\nsudo systemctl status prusa-connect-camera@csi.service\n</code></pre> <p>For another camera, let say for another camera attached over USB</p> <pre><code>cd /home/pi/src/prusa-connect-camera-script/\ncp usb.dist .usb1\n# edit .usb1 and set device, token and fingerprint etc...\nsudo systemctl enable prusa-connect-camera@usb1.service\nsudo systemctl start prusa-connect-camera@usb1.service\nsudo systemctl status prusa-connect-camera@usb1.service\n</code></pre> <p>For esphome camera, for static images:</p> <pre><code>cd /home/pi/src/prusa-connect-camera-script/\ncp esphome-snapshot.dist .esphome1\n# edit .esphome1 and set device, token and fingerprint etc...\nsudo systemctl enable prusa-connect-camera@esphome1.service\nsudo systemctl start prusa-connect-camera@esphome1.service\nsudo systemctl status prusa-connect-camera@esphome1.service\n</code></pre> <p>I hope you get the idea...</p>"},{"location":"service.systemd/#uninstall-systemd-service","title":"Uninstall systemd service","text":"<p>Just run two commands per camera (where <code>csi</code> is a camera config):</p> <pre><code>sudo systemctl stop prusa-connect-camera@csi.service\nsudo systemctl disable prusa-connect-camera@csi.service\n</code></pre> <p>After removing all cameras remove systemd service definition and reload daemon:</p> <pre><code>sudo rm -f /etc/systemd/system/prusa-connect-camera@.service\nsudo systemctl daemon-reload\n</code></pre>"},{"location":"stream.mediamtx/","title":"mediamtx","text":"<p>Use mediamtx to create camera streams.</p> <p>This is extremely convenient:</p> <ul> <li>easy to set up - single binary and single app config</li> <li>supports different hardware (linux/windows/raspberry-pi)</li> <li>supports various cameras ( USB / CSI) or remote streams   (push or transcode via ffmpeg)</li> <li>having local video streams from multiple cameras for local network   (you can proxy it further if you need)</li> <li>having different scripts to run to capture images from the stream and publish   them to Prusa Connect.</li> </ul> <p>So now you can have a cake and eat it in the same time!</p>"},{"location":"stream.mediamtx/#exposing-raspberry-pi-csi-camera","title":"Exposing Raspberry Pi CSI camera","text":"<p>Assuming you run mediamtx with Raspberry Pi CSI camera and that <code>rpi-address</code> is the hostname of your device and that you want to expose integrated CSI camera:</p> <ul> <li>CSI Raspberry Pi camera under /dev/video0</li> </ul> <p>so your <code>mediamtx.yml</code> has config fragment such as:</p> <pre><code>paths:\n  cam:\n    source: rpiCamera\n    rpiCameraWidth: 1920\n    rpiCameraHeight: 1080\n    rpiCameraHFlip: true\n    rpiCameraVFlip: true\n    # rpiCameraSaturation: 0 # uncomment if you have NoIR camera and you want to remove pink color overlay\n</code></pre> <p>Start mediamtx server:</p> <pre><code>./mediamtx\n</code></pre> <p>This should allow us to reach the stream, replace <code>rpi-address</code> with the name of your Raspberry Pi hostname or IP address. The ports are default for mediamtx.</p> <p>On another host see the stream:</p> <pre><code>ffplay rtsp://rpi-address:8554/cam\n</code></pre> <p>Or you could watch it via web browser under endpoints such as</p> <pre><code>http://rpi-address:8889/cam\n</code></pre> <p>Now, in prusa-connect-camera-script you need to set up config like below:</p> <pre><code>PRINTER_ADDRESS=...\nPRUSA_CONNECT_CAMERA_TOKEN=...\nPRUSA_CONNECT_CAMERA_FINGERPRINT=...\nCAMERA_DEVICE=/dev/null\nCAMERA_COMMAND=ffmpeg\nCAMERA_COMMAND_EXTRA_PARAMS=\"-loglevel error -y -i 'rtsp://rpi-address:8554/cam' -f image2 -vframes 1 -pix_fmt yuv420p \"\n</code></pre> <p>and that's it.</p>"},{"location":"stream.mediamtx/#example-with-single-camera-over-usb","title":"Example with single camera over USB","text":"<p>Raspberry Pi Zero 2 + Logitech C920, thanks to user [&amp;] undso.io for working example. Rpi zero hostname is <code>rpizero-ip</code>.</p> <p>Allows to have a camera live stream and prusa camera script to use that stream as source of the images to send to Prusa Connect.</p> <p>mediamtx config fragment</p> <pre><code>paths:\n  camusb:\n    runOnInit: ffmpeg -f v4l2 -i /dev/video0 -pix_fmt yuv420p -video_size 1920x1080 -framerate 30 -preset ultrafast -c:v libx264 -b:v 6000k -f rtsp rtsp://localhost:$RTSP_PORT/$MTX_PATH\n    runOnInitRestart: yes\n</code></pre> <p>So now you camera over usb should be available via <code>rtsp://rpizero-ip:8554/camusb</code></p> <p>Below is an env file for prusa connect script, remember to replace <code>rpizero-ip</code> with device address (or try <code>127.0.0.1</code> or <code>0.0.0.0</code> if script runs on the same host where mediamtx runs):</p> <pre><code>PRINTER_ADDRESS=...\nPRUSA_CONNECT_CAMERA_TOKEN=...\nPRUSA_CONNECT_CAMERA_FINGERPRINT=...\nCAMERA_DEVICE=/dev/null\nCAMERA_COMMAND=ffmpeg\nCAMERA_COMMAND_EXTRA_PARAMS=\"-loglevel error -y -i 'rtsp://rpizero-ip:8554/camusb' -f image2 -vframes 1 -pix_fmt yuv420p \"\n</code></pre>"},{"location":"stream.mediamtx/#exposing-two-cameras","title":"Exposing two cameras","text":"<p>Assuming you run mediamtx with Raspberry Pi CSI camera and that <code>rpi-address</code> is the hostname of your device and that you expose two cams:</p> <ul> <li>CSI Raspberry Pi camera under /dev/video0 (referenced as cam)</li> <li>USB camera under /dev/video1 (referenced as endoscope)</li> </ul> <p>so your <code>mediamtx.yml</code> has config fragment such as:</p> <pre><code>paths:\n  cam:\n    source: rpiCamera\n\n  endoscope:\n    runOnInit: ffmpeg -f v4l2 -pix_fmt mjpeg -video_size 1280x960 -framerate 30 -i /dev/video1 -c:v libx264 -preset ultrafast -b:v 6000k -f rtsp rtsp://localhost:$RTSP_PORT/$MTX_PATH\n    runOnInitRestart: yes\n</code></pre> <p>Start mediamtx server:</p> <pre><code>./mediamtx\n</code></pre> <p>This should allow you to reach two streams, replace <code>rpi-address</code> with the name of your Raspberry Pi hostname or IP address. The ports are default for mediamtx.</p> <pre><code>ffplay rtsp://rpi-address:8554/cam\nffplay rtsp://rpi-address:8554/endoscope\n</code></pre> <p>Or you could watch it via web browser under endpoints such as</p> <pre><code>http://rpi-address:8889/cam\nhttp://rpi-address:8889/endoscope\n</code></pre> <p>Now you can spawn two separate prusa-connect-camera-script instances with a separate env file for each, notice they differ only with the path to the rtsp stream url.</p> <p>CSI camera:</p> <pre><code>PRINTER_ADDRESS=...\nPRUSA_CONNECT_CAMERA_TOKEN=...\nPRUSA_CONNECT_CAMERA_FINGERPRINT=...\nCAMERA_DEVICE=/dev/null\nCAMERA_COMMAND=ffmpeg\nCAMERA_COMMAND_EXTRA_PARAMS=\"-loglevel error -y -i 'rtsp://rpi-address:8554/cam' -f image2 -vframes 1 -pix_fmt yuv420p \"\n</code></pre> <p>Endoscope camera:</p> <pre><code>PRINTER_ADDRESS=...\nPRUSA_CONNECT_CAMERA_TOKEN=...\nPRUSA_CONNECT_CAMERA_FINGERPRINT=...\nCAMERA_DEVICE=/dev/null\nCAMERA_COMMAND=ffmpeg\nCAMERA_COMMAND_EXTRA_PARAMS=\"-loglevel error -y -i 'rtsp://rpi-address:8554/endoscope' -f image2 -vframes 1 -pix_fmt yuv420p \"\n</code></pre>"},{"location":"stream.mediamtx/#formats","title":"Formats","text":"<p>Below examples are via rtsp protocol.</p> <p>FFmpeg does not support WebRTC (as of the moment of writing).</p> <p>If you want to use HLS then try something like <code>http://rpi-address:8554/cam/index.m3u8</code> as an input (just use <code>http://</code> and add <code>index.m3u8</code>).</p>"},{"location":"stream.mediamtx/#mediamtx-in-docker","title":"mediamtx in docker","text":"<p>See this PR or the code in here.</p>"},{"location":"test.config/","title":"Test the config","text":"<ul> <li>ensure to turn on the 3D Printer so that it sends telemetry, otherwise images   will sent and you will get successful image uploads but on Prusa Connect page   they will not be available</li> <li>run below commands, we assume <code>.env</code> is the camera config we defined earlier</li> </ul> <pre><code>set -o allexport; source .env; set +o allexport\n./prusa-connect-camera.sh\n</code></pre> <p>Above commands will load env vars and will start the script. In the beginning script shows some commands that will be executed, for example command to fetch the image from camera, example log line:</p> <pre><code>Camera capture command: fswebcam -d /dev/video0 --resolution 640x480 --no-banner /dev/shm/camera_87299de9-ea57-45be-b6ea-4d388a52c954.jpg\n</code></pre> <p>so you should run:</p> <pre><code>fswebcam -d /dev/video0 --resolution 640x480 --no-banner /dev/shm/camera_87299de9-ea57-45be-b6ea-4d388a52c954.jpg\n</code></pre> <p>and get the outputs from the command, and also it should write an image.</p> <p>Check for errors, if any, if everything is ok you should see a lot of <code>204</code> every 10s.</p> <p>If not, see troubleshooting, copy logs and raise an issue on GitHub.</p>"},{"location":"troubleshooting/","title":"Troubleshooting","text":"<p>Things to check if it does not work.</p>"},{"location":"troubleshooting/#general","title":"General","text":"<ul> <li> <p>some USB cameras require physical unplugging/plug-in AFTER   the Raspberry Pi was turned on, there is no fix for this yet, see   raspberrypi/linux/issues/6255   for such example</p> </li> <li> <p>check <code>/dev/shm/camera_*.stdout</code> and <code>/dev/shm/camera_*.stderr</code>   files for more details - if they state that 'everything is okay'   then probably you have issues with permissions when running script   for the second time (see below)</p> </li> <li> <p>check that the Prusa Connect <code>cameras</code> service   is running</p> </li> </ul>"},{"location":"troubleshooting/#system-file-permissions","title":"System file permissions","text":"<p>Check files under <code>/dev/shm/camera*</code> and <code>/dev/video0</code></p> <pre><code>ls -la /dev/shm/camera* /dev/video*\n</code></pre> <p>and compare them with the current user executing the script or the user that is running docker (see below) or systemd service (see section below).</p> <p>The quickest fix is just to delete files in <code>/dev/shm/camera_*</code> to fix only specific permission issues:</p> <pre><code>sudo systemctl stop prusa-connect-camera@env.service\nsudo rm -f /dev/shm/camera_*\nsudo systemctl start prusa-connect-camera@env.service\n</code></pre> <p>and see if the issue is resolved.</p> <p>If you still have issues due to accessing <code>/dev/video*</code> then ensure the user is added to <code>video</code> group.</p>"},{"location":"troubleshooting/#physical","title":"Physical","text":"<p>Check if the camera actually works - check cables if they are not damaged, if the cables are properly plugged, if the camera connects to the network... Some cameras when accessed will turn on led light showing that they are used.</p>"},{"location":"troubleshooting/#networking","title":"Networking","text":"<ul> <li> <p>if you use feature to ping the printer then ensure printer is up and running   and responds to ping, or just disable the feature (set <code>PRINTER_ADDRESS=\"\"</code> or   to <code>PRINTER_ADDRESS=127.0.0.1</code>), also make sure to allow ICMP protocol   on the firewalls on the target and on docker host</p> </li> <li> <p>check IP/domain names for remote camera - try that you can access camera over   IP address, otherwise you have a DNS issues.</p> </li> </ul>"},{"location":"troubleshooting/#camera-parameters","title":"Camera Parameters","text":"<ul> <li>check if the camera supports passed parameters such as resolution and codec,   especially after replacing the camera - see tuning   how to use <code>v4l2-ctl</code> to see available camera options.</li> </ul>"},{"location":"troubleshooting/#other-camera-apps","title":"Other camera apps","text":"<p>Check if any other app is not accessing the camera - especially local cameras are locked by another processes.</p> <p>If another application is accessing camera then unfortunately by default only one app can access the camera and you must decide which app to run.</p> <p>This means if you have something like Klipper/Obico/PrusaLink/motioneye/frigate (and so on) accessing the directly attached device to the Raspberry Pi then it will not work.</p> <p>In such case you can try to find the process using <code>fuser</code> package, assuming <code>/dev/video0</code> is your camera:</p> <pre><code>sudo apt install -y psmisc\nfuser /dev/video0\n</code></pre> <p>See StackOverflow for more details.</p> <p>In general you could create a loopback camera device but this is quite a lot of work to do.</p>"},{"location":"troubleshooting/#docker-troubleshooting","title":"Docker troubleshooting","text":"<ul> <li> <p>dockerized script - ensure you restart the pi after adding docker,   check user permissions to the mounted files and devices (unfortunately this can   get very messy with direct access to the devices and files on the host)</p> </li> <li> <p>check IP/domain names for remote camera - ensure that you can access camera   over IP address (or fully qualified domain name), because <code>.local</code> or <code>.lan</code>   domains are not resolved. Another option is to reconfigure docker to use proper   local DNS servers and not generic <code>8.8.8.8</code>.</p> </li> </ul> <p>You can also try to run container with --add-host   or   extra_hosts   in docker-compose.</p> <p>Another option is to run container with --network=\"host\"   or   network_mode: \"host\"   in docker-compose, but this is not recommended.</p>"},{"location":"troubleshooting/#systemd-troubleshooting","title":"Systemd troubleshooting","text":""},{"location":"troubleshooting/#get-systemd-logs","title":"Get systemd logs","text":"<p>If the script runs locally but service is not running then you can get the logs like below, ensure to replace <code>env</code> with the name your camera is using:</p> <ul> <li>stop service</li> </ul> <pre><code>sudo systemctl stop prusa-connect-camera@env.service\n</code></pre> <ul> <li>open new terminal and type:</li> </ul> <pre><code>sudo journalctl -f -u prusa-connect-camera\n</code></pre> <p>and keep it open</p> <ul> <li>get back to the first terminal and write commands:</li> </ul> <pre><code>sudo systemctl start prusa-connect-camera@env.service\nsleep 10\nsudo systemctl stop prusa-connect-camera@env.service\n</code></pre> <ul> <li> <p>get back to the terminal with running journalctl and see the logs   and look carefully at the errors described there</p> </li> <li> <p>copy the output from <code>starting</code> to the another <code>starting</code> command and paste   on GitHub</p> </li> </ul>"},{"location":"troubleshooting/#permissions-issues","title":"Permissions issues","text":"<p>Check if the user used in systemd file is the same as the one which executed test command - and you can edit systemd unit file via <code>nano</code> editor</p> <pre><code>sudo nano /etc/systemd/system/prusa-connect-camera@.service\n</code></pre> <p>and replace <code>User=pi</code> and <code>Group=pi</code> with the current user and group, then reload systemd and start service again</p> <pre><code>sudo systemctl daemon-reload\nsudo systemctl start prusa-connect-camera@env.service\n</code></pre> <p>This way it will use your user account to access camera device and write files.</p>"}]}